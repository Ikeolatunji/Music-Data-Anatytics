{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e83c31d-c45f-43f5-9384-26a9d13e263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class DataExplorer:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Loads the dataset from a CSV file.\"\"\"\n",
    "        self.data = pd.read_csv(self.file_path)\n",
    "        return self.data\n",
    "    \n",
    "    def _check_data_loaded(self):\n",
    "        \"\"\"Helper method to ensure data is loaded before processing.\"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Data not loaded. Please call load_data() first.\")\n",
    "\n",
    "    def check_missing_values(self):\n",
    "        \"\"\"Checks for missing values in the dataset.\"\"\"\n",
    "        self._check_data_loaded()\n",
    "        return self.data.isnull().sum()\n",
    "    \n",
    "    def describe_data(self):\n",
    "        \"\"\"Returns statistical description of the dataset.\"\"\"\n",
    "        self._check_data_loaded()\n",
    "        return self.data.describe()\n",
    "    \n",
    "    def visualize_distribution(self, column):\n",
    "        \"\"\"Plots the distribution of a given column.\"\"\"\n",
    "        self._check_data_loaded()\n",
    "        if column not in self.data.columns:\n",
    "            raise KeyError(f\"Column '{column}' not found in dataset.\")\n",
    "        \n",
    "        plt.hist(self.data[column].dropna(), bins=20, edgecolor='black')\n",
    "        plt.title(f'Distribution of {column}')\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.show()\n",
    "    \n",
    "    def bar_plot(self, column):\n",
    "        \"\"\"Creates a bar plot for categorical variables.\"\"\"\n",
    "        self._check_data_loaded()\n",
    "        if column not in self.data.columns:\n",
    "            raise KeyError(f\"Column '{column}' not found in dataset.\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.countplot(x=self.data[column], palette='viridis')\n",
    "        plt.title(f'Bar Plot of {column}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "    \n",
    "    def box_plot(self, column):\n",
    "        \"\"\"Creates a box plot for numerical variables.\"\"\"\n",
    "        self._check_data_loaded()\n",
    "        if column not in self.data.columns:\n",
    "            raise KeyError(f\"Column '{column}' not found in dataset.\")\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.boxplot(y=self.data[column], palette='coolwarm')\n",
    "        plt.title(f'Box Plot of {column}')\n",
    "        plt.show()\n",
    "    \n",
    "    def scatter_plot(self, x_col, y_col):\n",
    "        \"\"\"Creates a scatter plot to find relationships between two numerical variables.\"\"\"\n",
    "        self._check_data_loaded()\n",
    "        if x_col not in self.data.columns or y_col not in self.data.columns:\n",
    "            raise KeyError(f\"Columns '{x_col}' or '{y_col}' not found in dataset.\")\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.scatterplot(x=self.data[x_col], y=self.data[y_col], alpha=0.7)\n",
    "        plt.title(f'Scatter Plot of {x_col} vs {y_col}')\n",
    "        plt.show()\n",
    "\n",
    "class AdditionalStatistics:\n",
    "    \"\"\"Provides additional statistical measures for a given dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        if df is None or df.empty:\n",
    "            raise ValueError(\"DataFrame is empty or not loaded.\")\n",
    "        self.df = df\n",
    "\n",
    "    def _check_column_exists(self, column_name):\n",
    "        \"\"\"Helper method to check if column exists.\"\"\"\n",
    "        if column_name not in self.df.columns:\n",
    "            raise KeyError(f\"Column '{column_name}' not found in dataset.\")\n",
    "    \n",
    "    def mean(self, column_name):\n",
    "        self._check_column_exists(column_name)\n",
    "        return self.df[column_name].mean()\n",
    "\n",
    "    def median(self, column_name):\n",
    "        self._check_column_exists(column_name)\n",
    "        return self.df[column_name].median()\n",
    "\n",
    "    def std(self, column_name):\n",
    "        self._check_column_exists(column_name)\n",
    "        return self.df[column_name].std()\n",
    "\n",
    "    def variance(self, column_name):\n",
    "        self._check_column_exists(column_name)\n",
    "        return self.df[column_name].var()\n",
    "\n",
    "    def minimum(self, column_name):\n",
    "        self._check_column_exists(column_name)\n",
    "        return self.df[column_name].min()\n",
    "\n",
    "    def maximum(self, column_name):\n",
    "        self._check_column_exists(column_name)\n",
    "        return self.df[column_name].max()\n",
    "\n",
    "    def skewness(self, column_name):\n",
    "        self._check_column_exists(column_name)\n",
    "        return self.df[column_name].skew()\n",
    "\n",
    "    def kurtosis(self, column_name):\n",
    "        self._check_column_exists(column_name)\n",
    "        return self.df[column_name].kurtosis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e8d26f-3e5a-4883-86cd-d14838965549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, data, genres_data=None):\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input data must be a pandas DataFrame.\")\n",
    "        self.data = data.copy()\n",
    "        self.genres_data = genres_data.copy() if genres_data is not None else None\n",
    "    \n",
    "    def handle_missing_values(self, columns=None):\n",
    "        \"\"\"Handles missing values by filling numeric columns with their mean (or specified columns).\"\"\"\n",
    "        if columns:\n",
    "            self.data[columns] = self.data[columns].fillna(self.data[columns].mean())\n",
    "        else:\n",
    "            numeric_cols = self.data.select_dtypes(include=[np.number]).columns\n",
    "            self.data[numeric_cols] = self.data[numeric_cols].fillna(self.data[numeric_cols].mean())\n",
    "        return self.data\n",
    "    \n",
    "    def convert_dtypes(self):\n",
    "        \"\"\"Converts data types for consistency.\"\"\"\n",
    "        self.data['year'] = self.data['year'].astype(int)\n",
    "        self.data['explicit'] = self.data['explicit'].astype(bool)\n",
    "        return self.data\n",
    "    \n",
    "    def merge_genres(self):\n",
    "        \"\"\"Merges the main dataset with the genres dataset on 'id', if available.\"\"\"\n",
    "        if self.genres_data is not None and 'id' in self.data.columns and 'id' in self.genres_data.columns:\n",
    "            self.data = self.data.merge(self.genres_data, on='id', how='left')\n",
    "        return self.data\n",
    "    \n",
    "    def split_data(self, target_column, test_size=0.2):\n",
    "        \"\"\"Splits the dataset into training and testing sets.\"\"\"\n",
    "        if target_column not in self.data.columns:\n",
    "            raise KeyError(f\"Target column '{target_column}' not found in dataset.\")\n",
    "        \n",
    "        X = self.data.drop(columns=[target_column])\n",
    "        y = self.data[target_column]\n",
    "        return train_test_split(X, y, test_size=test_size, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af21bd2-0676-4d3b-8ee3-dbcc5bd3418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "class RecommendationSystem:\n",
    "    def __init__(self, data, feature_columns):\n",
    "        self.data = data\n",
    "        self.feature_columns = feature_columns\n",
    "    \n",
    "\n",
    "    def compute_similarity(self, target_row, chunkSize=None):\n",
    "        \"\"\"Computes similarity between songs based on selected features.\"\"\"\n",
    "        \n",
    "        features = self.data[self.feature_columns].head(chunkSize)\n",
    "\n",
    "        # Normalize the data\n",
    "        normalized_data = normalize(features)\n",
    "\n",
    "        # Convert features to sparse matrix (if necessary)\n",
    "        sparse_matrix = csr_matrix(normalized_data)\n",
    "\n",
    "        # Ensure we are using float32 for memory efficiency\n",
    "        data = sparse_matrix.astype(np.float32)\n",
    "\n",
    "        # Ensure chunk_data is always defined\n",
    "        chunk_data = data  # Default to the full dataset in case chunkSize condition is not met\n",
    "\n",
    "        if chunkSize and data.shape[0] > chunkSize:\n",
    "            start_idx = (target_row // chunkSize) * chunkSize\n",
    "            end_idx = min(start_idx + chunkSize, data.shape[0])\n",
    "            chunk_data = data[start_idx:end_idx]\n",
    "\n",
    "            target_vector = data[target_row]  # Extract the target row\n",
    "\n",
    "            # Compute similarity only for the chunk\n",
    "            similarity_scores = cosine_similarity(chunk_data, target_vector, dense_output=False).toarray().flatten()\n",
    "        else:\n",
    "            # Compute similarity for the entire dataset\n",
    "            target_vector = data[target_row]\n",
    "            similarity_scores = cosine_similarity(chunk_data, target_vector, dense_output=False).toarray().flatten()\n",
    "\n",
    "        return similarity_scores\n",
    "\n",
    "    \n",
    "    def recommend(self, song_index, top_n=5):\n",
    "        \"\"\"Recommends top N similar songs.\"\"\"\n",
    "        similarity_matrix = self.compute_similarity(song_index)\n",
    "\n",
    "        top_n_indices = np.argpartition(similarity_matrix, -top_n)[-top_n:]\n",
    "        top_n_indices = top_n_indices[np.argsort(similarity_matrix[top_n_indices])[::-1]]\n",
    "        similar_songs = np.argsort(similarity_matrix[top_n_indices])[::-1]\n",
    "        return self.data.iloc[top_n_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7865426-ed94-4155-b00b-7458787331fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "class SongClustering:\n",
    "    def __init__(self, df, feature_columns, name_column=\"artists\", n_clusters=3):\n",
    "        \"\"\"\n",
    "        Initialize the SongClustering class.\n",
    "\n",
    "        :param df: Pandas DataFrame containing song data.\n",
    "        :param feature_columns: List of feature columns to use for clustering.\n",
    "        :param name_column: Column name for artist names (default: 'artists').\n",
    "        :param n_clusters: Number of clusters for KMeans (default: 3).\n",
    "        \"\"\"\n",
    "        self.df = df.copy()  # Keep full dataset for recommendations\n",
    "        self.data = df[feature_columns].copy()  # Only feature columns for clustering\n",
    "        self.name_column = name_column\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "    def split_features(self, test_size=0.2, random_state=42):\n",
    "        \"\"\"\n",
    "        Splits feature data into training and testing sets.\n",
    "        \"\"\"\n",
    "        return train_test_split(self.data, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    def create_clusters(self):\n",
    "        \"\"\"\n",
    "        Applies KMeans clustering using selected features.\n",
    "        Assigns clusters to the full dataset (`self.df`).\n",
    "        \"\"\"\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=100, n_init=10)\n",
    "        self.df[\"cluster\"] = kmeans.fit_predict(self.data)  # Use feature data for clustering\n",
    "        self.data[\"cluster\"] = self.df[\"cluster\"]  # Add cluster labels to feature DataFrame\n",
    "\n",
    "    def visualize_clusters(self, based_on=[\"popularity\", \"tempo\"]):\n",
    "        \"\"\"\n",
    "        Visualizes clusters using a scatter plot.\n",
    "\n",
    "        :param based_on: List containing two feature names for visualization.\n",
    "        \"\"\"\n",
    "        if len(based_on) != 2:\n",
    "            raise ValueError(\"based_on should contain exactly two feature names.\")\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(x=self.df[based_on[0]], y=self.df[based_on[1]], \n",
    "                        hue=self.df['cluster'], palette='viridis', alpha=0.7)\n",
    "        plt.title(\"K-Means Clustering Visualization\")\n",
    "        plt.show()\n",
    "\n",
    "    def get_recommendations_by_cluster(self, artist_name, n=5):\n",
    "        \"\"\"\n",
    "        Recommends songs from the same cluster as the given artist.\n",
    "\n",
    "        :param artist_name: Artist name for whom to find recommendations.\n",
    "        :param n: Number of recommendations to return (default: 5).\n",
    "        \"\"\"\n",
    "        target_index = self.get_random_artist_index_by_name(artist_name)\n",
    "       \n",
    "        \n",
    "        if target_index is None:\n",
    "            return None\n",
    "\n",
    "        target_cluster = self.df.iloc[target_index][\"cluster\"]\n",
    "        recommended_songs = self.df[self.df[\"cluster\"] == target_cluster]\n",
    "\n",
    "        # Filter based on popularity range\n",
    "        target_popularity = self.df.iloc[target_index][\"popularity\"]\n",
    "        filtered = recommended_songs[\n",
    "            (recommended_songs[\"popularity\"] >= target_popularity - 10) &\n",
    "            (recommended_songs[\"popularity\"] <= target_popularity + 10)\n",
    "        ]\n",
    "\n",
    "        # If not enough recommendations, add extra\n",
    "        if len(filtered) < n:\n",
    "            additional = recommended_songs[~recommended_songs.index.isin(filtered.index)]\n",
    "            filtered = pd.concat([filtered, additional.head(n - len(filtered))])\n",
    "            \n",
    "        return filtered.head(n)\n",
    "    \n",
    "    def get_random_artist_index_by_name(self, artist_name):\n",
    "        \"\"\"\n",
    "        Finds an index of a random song by a given artist.\n",
    "        \"\"\"\n",
    "        # Use self.df since self.data does not contain the 'artists' column\n",
    "        artists=  self.df[self.name_column].tolist()\n",
    "\n",
    "        indexes = []\n",
    "\n",
    "        # find all indexes of artists that contain the name\n",
    "        for x in range(len(artists)):\n",
    "            if artist_name.lower() in str(artists[x]).lower():\n",
    "                indexes.append(x)\n",
    "\n",
    "        # if no matches found, return None\n",
    "        if len(indexes) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            # return a random index from the found indexes\n",
    "            return indexes[random.randint(0, len(indexes))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa059a0a-5019-471a-a215-383e5f366240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataLoadingAndExploration as etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03bebd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangler = etl.DataExplorer(\"./data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8487a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  wrangler.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4def4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170653"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445e3b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0594</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.982</td>\n",
       "      <td>['Sergei Rachmaninoff', 'James Levine', 'Berli...</td>\n",
       "      <td>0.279</td>\n",
       "      <td>831667</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0</td>\n",
       "      <td>4BJqT0PrAfrxzMOxytFOIz</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.665</td>\n",
       "      <td>-20.096</td>\n",
       "      <td>1</td>\n",
       "      <td>Piano Concerto No. 3 in D Minor, Op. 30: III. ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>80.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9630</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.732</td>\n",
       "      <td>['Dennis Day']</td>\n",
       "      <td>0.819</td>\n",
       "      <td>180533</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0</td>\n",
       "      <td>7xPhfUan2yNtyFG0cUWkt8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-12.441</td>\n",
       "      <td>1</td>\n",
       "      <td>Clancy Lowered the Boom</td>\n",
       "      <td>5</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>60.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0394</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.961</td>\n",
       "      <td>['KHP Kridhamardawa Karaton Ngayogyakarta Hadi...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>500062</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0</td>\n",
       "      <td>1o6I8BglA6ylDMrIELygv1</td>\n",
       "      <td>0.913000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-14.850</td>\n",
       "      <td>1</td>\n",
       "      <td>Gati Bali</td>\n",
       "      <td>5</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>110.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1650</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.967</td>\n",
       "      <td>['Frank Parker']</td>\n",
       "      <td>0.275</td>\n",
       "      <td>210000</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0</td>\n",
       "      <td>3ftBPsC5vPBKxYSee08FDH</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>5</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-9.316</td>\n",
       "      <td>1</td>\n",
       "      <td>Danny Boy</td>\n",
       "      <td>3</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>100.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2530</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.957</td>\n",
       "      <td>['Phil Regan']</td>\n",
       "      <td>0.418</td>\n",
       "      <td>166693</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0</td>\n",
       "      <td>4d6HGyGT8e121BsdKmw9v6</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3</td>\n",
       "      <td>0.229</td>\n",
       "      <td>-10.096</td>\n",
       "      <td>1</td>\n",
       "      <td>When Irish Eyes Are Smiling</td>\n",
       "      <td>2</td>\n",
       "      <td>1921</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>101.665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valence  year  acousticness  \\\n",
       "0   0.0594  1921         0.982   \n",
       "1   0.9630  1921         0.732   \n",
       "2   0.0394  1921         0.961   \n",
       "3   0.1650  1921         0.967   \n",
       "4   0.2530  1921         0.957   \n",
       "\n",
       "                                             artists  danceability  \\\n",
       "0  ['Sergei Rachmaninoff', 'James Levine', 'Berli...         0.279   \n",
       "1                                     ['Dennis Day']         0.819   \n",
       "2  ['KHP Kridhamardawa Karaton Ngayogyakarta Hadi...         0.328   \n",
       "3                                   ['Frank Parker']         0.275   \n",
       "4                                     ['Phil Regan']         0.418   \n",
       "\n",
       "   duration_ms  energy  explicit                      id  instrumentalness  \\\n",
       "0       831667   0.211         0  4BJqT0PrAfrxzMOxytFOIz          0.878000   \n",
       "1       180533   0.341         0  7xPhfUan2yNtyFG0cUWkt8          0.000000   \n",
       "2       500062   0.166         0  1o6I8BglA6ylDMrIELygv1          0.913000   \n",
       "3       210000   0.309         0  3ftBPsC5vPBKxYSee08FDH          0.000028   \n",
       "4       166693   0.193         0  4d6HGyGT8e121BsdKmw9v6          0.000002   \n",
       "\n",
       "   key  liveness  loudness  mode  \\\n",
       "0   10     0.665   -20.096     1   \n",
       "1    7     0.160   -12.441     1   \n",
       "2    3     0.101   -14.850     1   \n",
       "3    5     0.381    -9.316     1   \n",
       "4    3     0.229   -10.096     1   \n",
       "\n",
       "                                                name  popularity release_date  \\\n",
       "0  Piano Concerto No. 3 in D Minor, Op. 30: III. ...           4         1921   \n",
       "1                            Clancy Lowered the Boom           5         1921   \n",
       "2                                          Gati Bali           5         1921   \n",
       "3                                          Danny Boy           3         1921   \n",
       "4                        When Irish Eyes Are Smiling           2         1921   \n",
       "\n",
       "   speechiness    tempo  \n",
       "0       0.0366   80.954  \n",
       "1       0.4150   60.936  \n",
       "2       0.0339  110.339  \n",
       "3       0.0354  100.109  \n",
       "4       0.0380  101.665  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "225e9bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valence             0\n",
       "year                0\n",
       "acousticness        0\n",
       "artists             0\n",
       "danceability        0\n",
       "duration_ms         0\n",
       "energy              0\n",
       "explicit            0\n",
       "id                  0\n",
       "instrumentalness    0\n",
       "key                 0\n",
       "liveness            0\n",
       "loudness            0\n",
       "mode                0\n",
       "name                0\n",
       "popularity          0\n",
       "release_date        0\n",
       "speechiness         0\n",
       "tempo               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrangler.check_missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e15a9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>popularity</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>1.706530e+05</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "      <td>170653.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.528587</td>\n",
       "      <td>1976.787241</td>\n",
       "      <td>0.502115</td>\n",
       "      <td>0.537396</td>\n",
       "      <td>2.309483e+05</td>\n",
       "      <td>0.482389</td>\n",
       "      <td>0.084575</td>\n",
       "      <td>0.167010</td>\n",
       "      <td>5.199844</td>\n",
       "      <td>0.205839</td>\n",
       "      <td>-11.467990</td>\n",
       "      <td>0.706902</td>\n",
       "      <td>31.431794</td>\n",
       "      <td>0.098393</td>\n",
       "      <td>116.861590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.263171</td>\n",
       "      <td>25.917853</td>\n",
       "      <td>0.376032</td>\n",
       "      <td>0.176138</td>\n",
       "      <td>1.261184e+05</td>\n",
       "      <td>0.267646</td>\n",
       "      <td>0.278249</td>\n",
       "      <td>0.313475</td>\n",
       "      <td>3.515094</td>\n",
       "      <td>0.174805</td>\n",
       "      <td>5.697943</td>\n",
       "      <td>0.455184</td>\n",
       "      <td>21.826615</td>\n",
       "      <td>0.162740</td>\n",
       "      <td>30.708533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1921.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.108000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.317000</td>\n",
       "      <td>1956.000000</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>1.698270e+05</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>-14.615000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>93.421000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>2.074670e+05</td>\n",
       "      <td>0.471000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>-10.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>114.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.747000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>2.624000e+05</td>\n",
       "      <td>0.703000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>-7.183000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>135.537000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>5.403500e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.855000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>243.507000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             valence           year   acousticness   danceability  \\\n",
       "count  170653.000000  170653.000000  170653.000000  170653.000000   \n",
       "mean        0.528587    1976.787241       0.502115       0.537396   \n",
       "std         0.263171      25.917853       0.376032       0.176138   \n",
       "min         0.000000    1921.000000       0.000000       0.000000   \n",
       "25%         0.317000    1956.000000       0.102000       0.415000   \n",
       "50%         0.540000    1977.000000       0.516000       0.548000   \n",
       "75%         0.747000    1999.000000       0.893000       0.668000   \n",
       "max         1.000000    2020.000000       0.996000       0.988000   \n",
       "\n",
       "        duration_ms         energy       explicit  instrumentalness  \\\n",
       "count  1.706530e+05  170653.000000  170653.000000     170653.000000   \n",
       "mean   2.309483e+05       0.482389       0.084575          0.167010   \n",
       "std    1.261184e+05       0.267646       0.278249          0.313475   \n",
       "min    5.108000e+03       0.000000       0.000000          0.000000   \n",
       "25%    1.698270e+05       0.255000       0.000000          0.000000   \n",
       "50%    2.074670e+05       0.471000       0.000000          0.000216   \n",
       "75%    2.624000e+05       0.703000       0.000000          0.102000   \n",
       "max    5.403500e+06       1.000000       1.000000          1.000000   \n",
       "\n",
       "                 key       liveness       loudness           mode  \\\n",
       "count  170653.000000  170653.000000  170653.000000  170653.000000   \n",
       "mean        5.199844       0.205839     -11.467990       0.706902   \n",
       "std         3.515094       0.174805       5.697943       0.455184   \n",
       "min         0.000000       0.000000     -60.000000       0.000000   \n",
       "25%         2.000000       0.098800     -14.615000       0.000000   \n",
       "50%         5.000000       0.136000     -10.580000       1.000000   \n",
       "75%         8.000000       0.261000      -7.183000       1.000000   \n",
       "max        11.000000       1.000000       3.855000       1.000000   \n",
       "\n",
       "          popularity    speechiness          tempo  \n",
       "count  170653.000000  170653.000000  170653.000000  \n",
       "mean       31.431794       0.098393     116.861590  \n",
       "std        21.826615       0.162740      30.708533  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%        11.000000       0.034900      93.421000  \n",
       "50%        33.000000       0.045000     114.729000  \n",
       "75%        48.000000       0.075600     135.537000  \n",
       "max       100.000000       0.970000     243.507000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrangler.describe_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d6e5033",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wrangler\u001b[38;5;241m.\u001b[39madditional_statistics()\n",
      "File \u001b[1;32mc:\\Users\\ikeol\\Downloads\\dataset\\DataLoadingAndExploration.py:30\u001b[0m, in \u001b[0;36mDataExplorer.additional_statistics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madditional_statistics\u001b[39m(\u001b[38;5;28mself\u001b[39m,columnName):\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculates mean, median, std, variance, min, max, skewness, and kurtosis.\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     stats \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 30\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[columnName]\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedian\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[columnName]\u001b[38;5;241m.\u001b[39mmedian(),\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStandard Deviation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[columnName]\u001b[38;5;241m.\u001b[39mstd(),\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariance\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[columnName]\u001b[38;5;241m.\u001b[39mvar(),\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimum\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[columnName]\u001b[38;5;241m.\u001b[39mmin(),\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaximum\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[columnName]\u001b[38;5;241m.\u001b[39mmax(),\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSkewness\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[columnName]\u001b[38;5;241m.\u001b[39mapply(skew),\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKurtosis\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[columnName]\u001b[38;5;241m.\u001b[39mapply(kurtosis)\n\u001b[0;32m     38\u001b[0m     }\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(stats)\n",
      "File \u001b[1;32mc:\\Users\\ikeol\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11693\u001b[0m, in \u001b[0;36mDataFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11685\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11687\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11691\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11692\u001b[0m ):\n\u001b[1;32m> 11693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mmean(axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  11694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11695\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ikeol\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12422\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ikeol\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  12378\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  12379\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ikeol\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11562\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11558\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  11560\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11561\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11562\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[0;32m  11563\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  11564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ikeol\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1500\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1498\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1500\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[0;32m   1501\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1503\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ikeol\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:404\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    407\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\Users\\ikeol\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11481\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[0;32m  11480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\ikeol\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ikeol\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\Users\\ikeol\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:719\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    716\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m    720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wrangler.additional_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "wra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
